{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 데이터 분할"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "데이터를 훈련 세트와 테스트 세트로 분할한다.    \n",
    "데이터를 분할하는 것은 모델의 성능을 검증하는데 매우 중요하므로 데이터 누수와 같은 문제가 발생하지 않도록 각별한 주의가 필요하다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import spacy\n",
    "import umap\n",
    "import numpy as np \n",
    "from pathlib import Path\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from ml_editor.data_processing import format_raw_df, get_random_train_test_split, get_vectorized_inputs_and_label, get_split_by_author\n",
    "\n",
    "data_path = Path('./data/processed/writers/writers.csv')\n",
    "df = pd.read_csv(data_path, index_col=0)\n",
    "df = format_raw_df(df.copy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 랜덤 분할"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "가장 간단한 방법: 기준없이 랜덤하게 나눈다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_rand, test_df_rand = get_random_train_test_split(df[df[\"is_question\"]], test_size=0.3, random_state=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 세트: 7911개 질문, 테스트 세트: 3391개 질문\n",
      "훈련 세트에 있는 작성자: 7911명\n",
      "테스트 세트에 있는 작성자: 3391명\n",
      "양쪽에 모두 등장하는 작성자: 758명\n"
     ]
    }
   ],
   "source": [
    "print(\"훈련 세트: %s개 질문, 테스트 세트: %s개 질문\" % (len(train_df_rand),len(test_df_rand)))\n",
    "train_owners = set(train_df_rand['OwnerUserId'].values)\n",
    "test_owners = set(test_df_rand['OwnerUserId'].values)\n",
    "print(\"훈련 세트에 있는 작성자: %s명\" % len(train_df_rand))\n",
    "print(\"테스트 세트에 있는 작성자: %s명\" % len(test_df_rand))\n",
    "print(\"양쪽에 모두 등장하는 작성자: %s명\" % len(train_owners.intersection(test_owners)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "데이터를 분할하기 매우 쉬운 방법이지만, 같은 작성자가 쓴 질문들의 경우 유사한 패턴이 있을 수 있다.    \n",
    "따라서 같은 작성자가 작성한 질문들을 훈련과 테스트 세트에 모두 분배할 경우 작성자를 특정하여 예측을 수행하는 데이터 누수 문제가 발생할 수 있다.\n",
    "=> 데이터 분할 시 질문 단위가 아니라 작성자 단위로 분할하는 것이 좋다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 작성자 기준으로 분할"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 세트: 8161개 질문, 테스트 세트: 3141개 질문\n",
      "훈련 세트에 있는 작성자: 3752명\n",
      "훈련 세트에 있는 작성자: 1608명\n",
      "양쪽에 모두 등장하는 작성자: 0명\n"
     ]
    }
   ],
   "source": [
    "train_author, test_author = get_split_by_author(df[df[\"is_question\"]], test_size=0.3, random_state=40)\n",
    "\n",
    "print(\"훈련 세트: %s개 질문, 테스트 세트: %s개 질문\" % (len(train_author),len(test_author)))\n",
    "train_owners = set(train_author['OwnerUserId'].values)\n",
    "test_owners = set(test_author['OwnerUserId'].values)\n",
    "print(\"훈련 세트에 있는 작성자: %s명\" % len(train_owners))\n",
    "print(\"훈련 세트에 있는 작성자: %s명\" % len(test_owners))\n",
    "print(\"양쪽에 모두 등장하는 작성자: %s명\" % len(train_owners.intersection(test_owners)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-app",
   "language": "python",
   "name": "ml-app"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
